<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publication | Pan ZHOU </title> <meta name="author" content="Pan ZHOU"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/log.ico?cada1a831dbcff16e2bae7854c63d30d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://panzhou916.github.io/publication/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <b>Pan ZHOU</b> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> <b>Home</b> </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/"> <b>Research</b> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publication/"> <b>Publication</b> <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/"> <b>Teaching</b> </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/"> <b>Service</b> </a> </li> <li class="nav-item "> <a class="nav-link" href="/recruitment/"> <b>Recruitment</b> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publication</h1> <p class="post-description"></p> </header> <article> <p>You can also browse my <a href="https://scholar.google.com/citations?user=0b7ZqlcAAAAJ&amp;hl=en" target="_blank" style="text-decoration:underline;" rel="external nofollow noopener">Google Scholar profile</a>. <strong><sup>*</sup></strong> denotes equal contribution; <strong><sup>+</sup></strong> denotes corresponding author.</p> <p><br></p> <style>div.noshow{display:none}div.bibtex{margin-right:0;margin-top:1.2em;margin-bottom:1.3em;border:1px solid silver;padding:.3em .5em;background:#eee}div.bibtex pre{font-size:75%;overflow:auto;width:100%}</style> <script>function toggleBibtex(e){var s=document.getElementById("bib_"+e);s&&-1!=s.className.indexOf("bibtex")&&(-1==s.className.indexOf("noshow")?s.className="bibtex noshow":s.className="bibtex")}</script> <h5 id="featured-publications"><strong>Featured Publications</strong></h5> <ol class="biblist"> <li> <p> <strong>Masked Diffusion Transformer is a Strong Image Synthesizer</strong><br> Shanghua Gao, <strong>Pan Zhou<sup>+</sup></strong>, Ming-Ming Cheng, Shuicheng Yan<br> ICCV, 2023, <a href="https://arxiv.org/abs/2303.14389" style="color: black;" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/sail-sg/MDT" style="color: black;" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/MDT?style=social"> </iframe> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="400px" height="20px" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/masked-diffusion-transformer-is-a-strong/image-generation-on-imagenet-256x256"> </iframe><br> <font color="#2770AB"><b>SoTA image generative model</b> on ImageNet 256x256; <b>13x faster learning speed</b> than <a href="https://arxiv.org/abs/2212.09748" rel="external nofollow noopener" target="_blank">DiT</a> (core of <a href="https://openai.com/sora" rel="external nofollow noopener" target="_blank">SORA</a>) </font> <br> </p> </li> <li> <p> <strong>EditAnything: Empowering Unparalleled Flexibility in Image Editing and Generation</strong><br> Shanghua Gao, Zhijie Lin, Xingyu Xie, <strong>Pan Zhou<sup>+</sup></strong>, Ming-Ming Cheng, Shuicheng Yan<br> ACMMM, 2023, <a href="https://dl.acm.org/doi/10.1145/3581783.3612680" style="color: black;" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/sail-sg/EditAnything" style="color: black;" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/EditAnything?style=social"> </iframe><br> <font color="#2770AB"><b>the first a few pioneers for highly-flexible image editing,</b> e.g., cross-image dragging like try-on, region-interactive editing, controllable layout generation, and virtual character replacement. </font> <br> </p> </li> <li> <p> <strong>Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation with Deterministic Sampling Prior</strong><br> Zike Wu, <strong>Pan Zhou<sup>+</sup></strong>, Xuanyu YI, Xiaoding Yuan, Hanwang Zhang <br> CVPR, 2024, <a href="https://arxiv.org/abs/2401.09050" style="color: black;" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/Consistent3D" style="color: black;" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/Consistent3D?style=social"> </iframe><br> <font color="#2770AB"><b>the first ODE-sampling guided Score Distillation Sampling</b> for 3D generation</font> <br> </p> </li> <li> <p> <strong>Prototypical Contrastive Learning of Unsupervised Representations</strong><br> Junnan Li, <strong>Pan Zhou</strong>, Caiming Xiong, Steven Hoi<br> ICLR, 2021, <a href="https://openreview.net/pdf?id=KmykpuSrjcq" style="color: black;" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2021-ICLR-SSL.txt" style="color: black;">[Bibtex]</a> <a href="https://blog.einstein.ai/prototypical-contrastive-learning-pushing-the-frontiers-of-unsupervised-learning/" style="color: black;" rel="external nofollow noopener" target="_blank">[Blog]</a> <a href="https://github.com/salesforce/PCL" style="color: black;" rel="external nofollow noopener" target="_blank">[Code]</a>, 900+ citations, <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/salesforce/PCL?style=social"> </iframe><br> <font color="#2770AB"><b>the first clustering contrastive learning method to learn high-level semantics, i.e., data cluster structure</b></font> <br> </p> </li> <li> <p> <strong>MetaFormer Baselines for Vision</strong><br> Weihao Yu, Chenyang Si, <strong>Pan Zhou</strong>, Mi Luo, Yichen Zhou, Jiashi Feng, Shuicheng Yan, Xinchao Wang<br> TPAMI &amp; CVPR, 2023, <a href="https://arxiv.org/abs/2111.11418#:~:text=Based%20on%20the%20extensive%20experiments,on%20the%20token%20mixer%20modules" style="color: black;" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/poolformer" style="color: black;" rel="external nofollow noopener" target="_blank">[Code]</a>, 600+ citations, <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/poolformer?style=social"> </iframe> <br> <font color="#2770AB"><b>replacing attention with simple pooling still achieves high performance, breaking "attention is all you need" and revealing network design principle</b></font> <br> </p> </li> <li> <p> <strong>Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models</strong><br> Xingyu Xie<strong><sup>*</sup></strong>, <strong>Pan Zhou</strong><strong><sup>*</sup></strong>, Huan Li, Zhouchen Lin, Shuicheng Yan <br> TPAMI, 2024 <a href="https://arxiv.org/abs/2208.06677" style="color: black;" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/sail-sg/Adan" style="color: black;" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/Adan?style=social"> </iframe><br> <font color="#2770AB"><b> 2X-faster and SoTA optimizer on 15+ networks</b> like ResNet, ConvNext, ViT, Swin, MAE, BERT, GPT2, LLAMA, Dreamfusion, DiT, PPO in RL, etc. <b>Included by popular deep-learning codebases</b> like <a href="https://github.com/NVIDIA/NeMo/blob/main/nemo/core/optim/adan.py" rel="external nofollow noopener" target="_blank">NVIDIA NeMo</a> for LLM, <a href="https://github.com/huggingface/pytorch-image-models/blob/main/timm/optim/adan.py" rel="external nofollow noopener" target="_blank">HuggingFace Timm</a> and <a href="https://github.com/open-mmlab/mmpretrain/blob/dev-1.x/mmcls/engine/optimizers/adan_t.py" rel="external nofollow noopener" target="_blank">OpenMMLab</a> for CV tasks, <a href="https://github.com/Jittor/jittor/blob/master/python/jittor/optim.py" rel="external nofollow noopener" target="_blank">Jittor of Tsinghua University</a> for 3D. </font> <br> </p> </li> <li> <p> <strong>Win: Weight-Decay-Integrated Nesterov Acceleration for Faster Network Training</strong><br> <strong>Pan Zhou</strong>, Xingyu Xie, Zhouchen Lin, Kim-Chuan Toh, Shuicheng Yan <br> JMLR &amp; ICLR, 2024 <a href="../assets/pdf/2024-JMLR-win.pdf" style="color: black;">[PDF]</a> <a href="https://github.com/sail-sg/win" style="color: black;" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px; color: black;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/win?style=social"> </iframe><br> <font color="#2770AB"><b>accelerate AdamW/Adam/LAMB/SGD by 1.5x on vision and language modeling tasks.</b></font> <br> </p> </li> <li> <p> <strong>Towards Theoretically Understanding Why SGD Generalizes Better Than ADAM in Deep Learning</strong><br> <strong>Pan Zhou</strong>, Jiashi Feng, Chao Ma, Caiming Xiong, Steven Hoi, and Weinan E<br> NeurIPS, 2020, <a href="../assets/pdf/2020_generalization.pdf" style="color: black;">[PDF]</a> <a href="../assets/pdf/2020_generalization_supp.pdf" style="color: black;">[SUPP]</a> <a href="https://arxiv.org/pdf/2010.05627.pdf" style="color: black;" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2020_generalization_bib.txt" style="color: black;">[Bibtex]</a> <a href="https://github.com/salesforce/comparison_SGD_ADAM" style="color: black;" rel="external nofollow noopener" target="_blank">[Code]</a> <a href="../assets/pdf/2020-NIPS-SGD-slides.pdf" style="color: black;">[Slides]</a> <a href="../assets/pdf/2020-NIPS-SGD-poster.pdf" style="color: black;">[Poster]</a>, 200+ citations <br> <font color="#2770AB"><b>the first theory to explain "why SGD generalizes better than ADAM in deep learning"</b></font> <br> </p> </li> </ol> <p><br></p> <h5 id="full-publications"><strong>Full Publications</strong></h5> <ol class="biblist"> <h4> <a name="2025"></a> 2025 </h4> <li> <p> <strong>LoCo: Low-Bit Communication Adaptor for Large-scale Model Training</strong><br> Xingyu Xie, Zhijie Lin, Kim-chuan Toh, <strong>Pan Zhou<sup>+</sup></strong><br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2025<br> <a href="https://arxiv.org/abs/2407.04480" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/deepspeedai/DeepSpeed/pull/6730" rel="external nofollow noopener" target="_blank">[Code]</a> <br> <b> On Megatron-LM and FSDP, LoCo significantly improves communication efficiency, e.g., +14% to +40% improvement on Adam's overall training speed without performance degradation on LLAMAs and MoEs. LoCo has been included by popular <a href="https://github.com/deepspeedai/DeepSpeed/pull/6730" rel="external nofollow noopener" target="_blank">DeepSpeed</a> codebase like <a href="https://github.com/deepspeedai/DeepSpeed/pull/6730" rel="external nofollow noopener" target="_blank">Zero++</a>. </b> <br> </p> </li> <li> <p> <strong>A Causality-aware Paradigm for Evaluating Creativity of Multimodal Large Language Models</strong><br> Zhongzhan Huang<sup>*</sup>, Shanshan Zhong<sup>*</sup>, <strong>Pan Zhou<sup>*</sup></strong>, Shanghua Gao, Marinka Zitnik, Liang Lin <br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2025<br> <a href="https://arxiv.org/abs/2501.15147" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://lotbench.github.io/" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://ghbtns.com/github-btn.html?user=sail-sg&amp;repo=CLoT&amp;type=star&amp;count=true"> </iframe> </p> </li> <li> <p> <strong>Gamba: Marry Gaussian Splatting with Mamba for Single-View 3D Reconstruction</strong><br> Qiuhong Shen, Zike Wu, Xuanyu Yi, <strong>Pan Zhou</strong>, Hanwang Zhang, Shuicheng Yan, Xinchao Wang <br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2025<br> <a href="https://arxiv.org/abs/2403.18795" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://florinshen.github.io/gamba-project/" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://ghbtns.com/github-btn.html?user=SkyworkAI&amp;repo=Gamba&amp;type=star&amp;count=true"> </iframe> </p> </li> <li> <p> <strong>HPS: Hard Preference Sampling for Human Preference Alignment</strong><br> Xiandong Zou, Wanyu Lin, Yuchen Li, <strong>Pan Zhou<sup>+</sup></strong><br> International Conference on Machine Learning (<strong>ICML</strong>), 2025 <br> <a href="https://arxiv.org/abs/2502.14400" rel="external nofollow noopener" target="_blank">[Axriv]</a> </p> </li> <li> <p> <strong>Probabilistic Interactive 3D Segmentation with Hierarchical Neural Processes</strong><br> Jie Liu, <strong>Pan Zhou<sup>+</sup></strong>, Zehao Xiao, Jiayi Shen, Wenzhe Yin, Jan-Jakob Sonke, Efstratios Gavves<br> International Conference on Machine Learning (<strong>ICML</strong>), 2025 <br> <a href="https://jliu4ai.github.io/media/NPISeg3D.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/jliu4ai/NPISeg3D" rel="external nofollow noopener" target="_blank">[Code]</a> <br> </p> </li> <li> <p> <strong>Collaborative Tree Search for Enhancing Embodied Multi-Agent Collaboration</strong><br> Lizheng Zu, Lin Lin, Song Fu, Na Zhao, <strong>Pan Zhou</strong> <br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025<br> <a href="../assets/pdf/2025-CVPR-CoTS.pdf">[PDF]</a> </p> </li> <li> <p> <strong>Towards Understanding Why FixMatch Generalizes Better Than Supervised Learning</strong><br> Jingyang Li, Jiachun Pan, Vincent Y. F. Tan, Kim-chuan Toh, <strong>Pan Zhou<sup>+</sup></strong><br> International Conference on Learning Representations (<strong>ICLR</strong>), 2025 (<strong>oral, 1.8% acceptance rate</strong>) <br> <a href="https://arxiv.org/abs/2410.11206" rel="external nofollow noopener" target="_blank">[Axriv]</a> </p> </li> <li> <p> <strong>CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation</strong><br> Jie Liu, <strong>Pan Zhou<sup>+</sup></strong>, Yingjun Du, Ah-Hwee Tan, Cees G. M. Snoek, Jan-Jakob Sonke, Efstratios Gavves <br> International Conference on Learning Representations (<strong>ICLR</strong>), 2025 <br> <a href="https://arxiv.org/abs/2411.04679" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/jliu4ai/CaPo" rel="external nofollow noopener" target="_blank">[Code]</a> <br> </p> </li> <h4> <a name="2024"></a> 2024 </h4> <li> <p> <strong>Win: Weight-Decay-Integrated Nesterov Acceleration for Faster Network Training</strong><br> <strong>Pan Zhou</strong>, Xingyu Xie, Zhouchen Lin, Kim-Chuan Toh, Shuicheng Yan <br> Journal of Machine Learning Research (<strong>JMLR</strong>), 2024<br> <a href="../assets/pdf/2024-JMLR-win.pdf">[PDF]</a> <a href="https://github.com/sail-sg/win" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/win?style=social"> </iframe> </p> </li> <li> <p> <strong>Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models</strong><br> Xingyu Xie<strong><sup>*</sup></strong>, <strong>Pan Zhou</strong><strong><sup>*</sup></strong>, Huan Li, Zhouchen Lin, Shuicheng Yan <br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2024<br> <a href="https://arxiv.org/abs/2208.06677" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/sail-sg/Adan" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/Adan?style=social"> </iframe><br> </p> </li> <li> <p> <strong>Instant3D: Instant Text-to-3D Generation</strong><br> Ming Li, <strong>Pan Zhou</strong>, Jia-Wei Liu, Jussi Keppo, Min Lin, Shuicheng Yan, Xiangyu Xu <br> International Journal of Computer Vision (<strong>IJCV</strong>), 2024<br> <a href="https://arxiv.org/abs/2311.08403" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://ming1993li.github.io/Instant3DProj/" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/ming1993li/Instant3DCodes?style=social"> </iframe> </p> </li> <li> <p> <strong>Enhancing Visual Grounding in Vision-Language Pre-Training with Position-Guided Text Prompts</strong><br> Alex Jinpeng Wang, <strong>Pan Zhou</strong>, Mike Zheng Shou, Shuicheng Yan <br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2024<br> <a href="https://ieeexplore.ieee.org/document/10363674" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/sail-sg/ptp" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/ptp?style=social"> </iframe>, <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="400px" height="20px" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/position-guided-text-prompt-for-vision/zero-shot-cross-modal-retrieval-on-coco-2014"> </iframe> </p> </li> <li> <p> <strong>Towards Understanding Convergence and Generalization of AdamW</strong><br> <strong>Pan Zhou</strong>, Xingyu Xie, Zhoucheng Lin, Shuicheng Yan <br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2024<br> <a href="../assets/pdf/2024-TPAMI-AdamW.pdf">[PDF]</a> <a href="../assets/pdf/2024-TPAMI-AdamW-supp.pdf">[Supp]</a> </p> </li> <li> <p> <strong>Unsupervised Modality Adaptation with Text-to-Image Diffusion Models for Semantic Segmentation</strong><br> Ruihao Xia, Yu Liang, Peng-Tao Jiang, Hao Zhang, Bo Li, Yang Tang, <strong>Pan Zhou</strong> <br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2024<br> <a href="https://arxiv.org/abs/2405.18144" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/XiaRho/MADM" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/XiaRho/MADM?style=social"> </iframe> </p> </li> <li> <p> <strong>LOVA3: Learning to Visual Question Answering, Asking and Assessment</strong><br> Hengyuan Zhao, <strong>Pan Zhou</strong><strong><sup>+</sup></strong>, Difei Gao, Mike Zheng Shou<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2024<br> <a href="https://arxiv.org/abs/2405.14974" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/showlab/LOVA3" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/showlab/LOVA3?style=social"> </iframe> </p> </li> <li> <p> <strong>4-bit Shampoo for Memory-Efficient Network Training</strong><br> Sike Wang, <strong>Pan Zhou</strong>, Jia Li, Hua Huang<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2024<br> <a href="https://arxiv.org/abs/2405.18144" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/Sike-Wang/low-bit-Shampoo" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/Sike-Wang/low-bit-Shampoo?style=social"> </iframe> </p> </li> <li> <p> <strong>MVGamba: Unify 3D Content Generation as State Space Sequence Modeling</strong><br> Xuanyu Yi, Zike Wu, Qiuhong Shen, Qingshan Xu, <strong>Pan Zhou</strong>, Joo Hwee Lim, Shuicheng YAN, Xinchao Wang, Hanwang Zhang<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2024<br> <a href="https://arxiv.org/abs/2406.06367" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/SkyworkAI/Gamba" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/SkyworkAI/Gamba?style=social"> </iframe> </p> </li> <li> <p> <strong>Genixer: Empowering Multimodal Large Language Models as a Powerful Data Generator</strong><br> Henry Hengyuan Zhao, <strong>Pan Zhou</strong><strong><sup>+</sup></strong>, Mike Zheng Shou <br> European Conference on Computer Vision (<strong>ECCV</strong>), 2024<br> <a href="https://arxiv.org/abs/2312.06731" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/zhaohengyuan1/Genixer" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/zhaohengyuan1/Genixer?style=social"> </iframe><br> </p> </li> <li> <p> <strong>Efficient Cascaded Multiscale Adaptive Network for Image Restoration</strong><br> Yichen Zhou, <strong>Pan Zhou</strong><strong><sup>+</sup></strong>, Teck Khim Ng <br> European Conference on Computer Vision (<strong>ECCV</strong>), 2024<br> </p> </li> <li> <p> <strong>Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Multimodal Humor Generation</strong><br> Shanshan Zhong, Zhongzhan Huang, Shanghua Gao, Wushao Wen, Liang Lin, Marinka Zitnik, <strong>Pan Zhou<sup>+</sup></strong><br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024<br> <a href="https://arxiv.org/abs/2312.02439" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://zhongshsh.github.io/CLoT/" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/CLoT?style=social"> </iframe> </p> </li> <li> <p> <strong>InceptionNeXt: When Inception Meets ConvNeXt</strong><br> Weihao Yu, <strong>Pan Zhou</strong>, Shuicheng YAN, Xinchao Wang <br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024<br> <a href="https://arxiv.org/abs/2303.16900" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/inceptionnext" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/inceptionnext?style=social"> </iframe> </p> </li> <li> <p> <strong>Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation with Deterministic Sampling Prior</strong><br> Zike Wu, <strong>Pan Zhou<sup>+</sup></strong>, Xuanyu YI, Xiaoding Yuan, Hanwang Zhang <br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024<br> <a href="https://arxiv.org/abs/2401.09050" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/Consistent3D" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/Consistent3D?style=social"> </iframe> </p> </li> <li> <p> <strong>Friendly Sharpness-Aware Minimization</strong><br> Tao Li, <strong>Pan Zhou<sup>+</sup></strong>, Zhengbao He, Xinwen Cheng, Xiaolin Huang<br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024<br> <a href="https://arxiv.org/abs/2403.12350" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/nblt/F-SAM" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/nblt/F-SAM?style=social"> </iframe> </p> </li> <li> <p> <strong>Few-shot Learner Parameterization by Diffusion Time-steps</strong><br> Zhongqi Yue, <strong>Pan Zhou<sup>+</sup></strong>, Richang Hong, Hanwang Zhang, Qianru Sun <br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024<br> <a href="https://arxiv.org/abs/2403.02649" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/yue-zhongqi/tif" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/yue-zhongqi/tif?style=social"> </iframe> </p> </li> <li> <p> <strong>Diffusion Time-step Curriculum for One Image to 3D Generation</strong><br> Xuanyu Yi, Zike Wu, Qingshan Xu, <strong>Pan Zhou<sup>+</sup></strong>, Joo Hwee Lim, Hanwang Zhang <br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024<br> <a href="https://github.com/yxymessi/DTC123/blob/main/DTC_CVPR.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/yxymessi/DTC123" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/yxymessi/DTC123?style=social"> </iframe> </p> </li> <h4> <a name="2023"></a> 2023 </h4> <li> <p> <strong>MetaFormer Baselines for Vision</strong><br> Weihao Yu, Chenyang Si, <strong>Pan Zhou</strong>, Mi Luo, Yichen Zhou, Jiashi Feng, Shuicheng Yan, Xinchao Wang<br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2023<br> <a href="https://arxiv.org/abs/2210.13452" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/metaformer" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/metaformer?style=social"> </iframe>, <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="700px" height="20px" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/metaformer-baselines-for-vision/domain-generalization-on-imagenet-c"> </iframe> </p> </li> <li> <p> <strong>Contrastive Video Question Answering via Video Graph Transformer</strong><br> Junbin Xiao, <strong>Pan Zhou</strong>, Angela Yao, Yicong Li, Richang Hong, Shuicheng Yan, Tat-Seng Chua<br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2023<br> <a href="https://arxiv.org/abs/2302.13668" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/doc-doc/CoVGT" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/doc-doc/CoVGT?style=social"> </iframe> </p> </li> <li> <p> <strong>Iterative Graph Self-Distillation</strong><br> Hanlin Zhang, Shuai Lin, Weiyang Liu, <strong>Pan Zhou</strong>, Jian Tang, Xiaodan Liang, Eric P. Xing <br> IEEE Transactions on Knowledge and Data Engineering (<strong>TKDE</strong>), 2023 <br> <a href="https://arxiv.org/abs/2010.12609" rel="external nofollow noopener" target="_blank">[Axriv]</a> </p> </li> <li> <p> <strong>ScaleLong: Towards More Stable Training of Diffusion Model via Scaling Network Long Skip Connection</strong><br> Zhongzhan Huang, <strong>Pan Zhou<sup>+</sup></strong>, Shuicheng Yan, Liang Lin<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2023<br> <a href="https://arxiv.org/pdf/2310.13545.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/ScaleLong" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/ScaleLong?style=social"> </iframe> </p> </li> <li> <p> <strong>Masked Diffusion Transformer is a Strong Image Synthesizer</strong><br> Shanghua Gao, <strong>Pan Zhou<sup>+</sup></strong>, Ming-Ming Cheng, Shuicheng Yan<br> International Conference on Computer Vision (<strong>ICCV</strong>), 2023<br> <a href="https://arxiv.org/abs/2303.14389" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/sail-sg/MDT" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/MDT?style=social"> </iframe> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="400px" height="20px" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/masked-diffusion-transformer-is-a-strong/image-generation-on-imagenet-256x256"> </iframe> </p> </li> <li> <p> <strong>EditAnything: Empowering Unparalleled Flexibility in Image Editing and Generation</strong><br> Shanghua Gao, Zhijie Lin, Xingyu Xie, <strong>Pan Zhou<sup>+</sup></strong>, Ming-Ming Cheng, Shuicheng Yan<br> ACM International Conference on Multimedia (<strong>ACMMM</strong>), 2023<br> <a href="https://dl.acm.org/doi/10.1145/3581783.3612680" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://github.com/sail-sg/EditAnything" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/EditAnything?style=social"> </iframe> </p> </li> <li> <p> <strong>STPrivacy: Spatio-Temporal Privacy-Preserving Action Recognition</strong><br> Ming Li, Xiangyu Xu, Hehe Fan, <strong>Pan Zhou</strong>, Jun Liu, Jia-Wei Liu, Jiahe Li, Jussi Keppo, Mike Zheng Shou, Shuicheng Yan<br> International Conference on Computer Vision (<strong>ICCV</strong>), 2023<br> <a href="https://arxiv.org/abs/2301.03046" rel="external nofollow noopener" target="_blank">[PDF]</a> </p> </li> <li> <p> <strong>Position-guided Text Prompt for Vision-Language Pre-training</strong><br> Alex Jinpeng Wang, <strong>Pan Zhou<sup>+</sup></strong>, Mike Zheng Shou, Shuicheng Yan <br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023<br> <a href="https://arxiv.org/pdf/2212.09737.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/ptp" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/ptp?style=social"> </iframe>, <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="400px" height="20px" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/position-guided-text-prompt-for-vision/zero-shot-cross-modal-retrieval-on-coco-2014"> </iframe> </p> </li> <li> <p> <strong>Win: Weight-Decay-Integrated Nesterov Acceleration for Adaptive Gradient Algorithms</strong><br> <strong>Pan Zhou</strong>, Xingyu Xie, Shuicheng Yan <br> International Conference on Learning Representations (<strong>ICLR</strong>), 2023 (<font color="#FF0000"><strong>oral</strong></font>)<br> <a href="https://openreview.net/pdf?id=CPdc77SQfQ5" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/win" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/win?style=social"> </iframe> </p> </li> <li> <p> <strong>Towards Understanding Why Mask Reconstruction Pretraining Helps in Downstream Tasks</strong><br> Jiachun Pan<strong><sup>*</sup></strong>, <strong>Pan Zhou</strong><strong><sup>*</sup></strong>, Shuicheng Yan<br> International Conference on Learning Representations (<strong>ICLR</strong>), 2023 <br> <a href="https://arxiv.org/pdf/2206.03826.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> </p> </li> <li> <p> <strong>LPT: Long-tailed Prompt Tuning for Image Classification</strong><br> Bowen Dong, <strong>Pan Zhou</strong>, Shuicheng Yan, Wangmeng Zuo <br> International Conference on Learning Representations (<strong>ICLR</strong>), 2023 <br> <a href="https://arxiv.org/abs/2210.01033" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/DongSky/LPT" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/DongSky/LPT?style=social"> </iframe>, <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="400px" height="20px" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/lpt-long-tailed-prompt-tuning-for-image/long-tail-learning-on-cifar-100-lt-r-100"> </iframe> </p> </li> <h4> <a name="2022"></a> 2022 </h4> <li> <p> <strong>Prototypical Graph Contrastive Learning</strong><br> Shuai Lin, Chen Liu, <strong>Pan Zhou</strong>, Zi-yuan Hu, Shuojia Wang, Ruihui Zhao, Yefeng Zheng, Liang Lin, Eric Xing, Xiaodan Liang<br> IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>), 2022 <br> <a href="https://arxiv.org/abs/2106.09645" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/ha-lins/PGCL" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/ha-lins/PGCL?style=social"> </iframe> </p> </li> <li> <p> <strong>Inception Transformer</strong><br> Chenyang Si<strong><sup>*</sup></strong>, Weihao Yu<strong><sup>*</sup></strong>, <strong>Pan Zhou</strong>, Yichen Zhou, Xinchao Wang, Shuicheng Yan<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022 (<font color="#FF0000"><strong>oral</strong></font>)<br> <a href="https://arxiv.org/abs/2205.12956" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/iFormer" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/iFormer?style=social"> </iframe> </p> </li> <li> <p> <strong>Mugs: A Multi-Granular Self-Supervised Learning Framework</strong><br> <strong>Pan Zhou</strong><strong><sup>*</sup></strong>, Yichen Zhou<strong><sup>*</sup></strong>, Chenyang Si<strong><sup>*</sup></strong>, Weihao Yu, Teck Khim Ng, Shuicheng Yan<br> Workshop of Neural Information Processing Systems, 2022.<br> <a href="https://arxiv.org/abs/2203.14415" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/mugs" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/mugs?style=social"> </iframe> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="400px" height="20px" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/mugs-a-multi-granular-self-supervised/self-supervised-image-classification-on"> </iframe><br> <font color="#2770AB"><b>Top linear probing and KNN performance on ImageNet without extra data</b></font><br> </p> </li> <li> <p> <strong>DualFormer: Local-Global Stratified Transformer for Efficient Video Recognition</strong><br> Yuxuan Liang, <strong>Pan Zhou</strong>, Roger Zimmermann, Shuicheng Yan <br> European Conference on Computer Vision (<strong>ECCV</strong>), 2022 <br> <a href="https://arxiv.org/abs/2112.04674" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/dualformer" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/dualformer?style=social"> </iframe> </p> </li> <li> <p> <strong>Video Graph Transformer for Video Question Answering</strong><br> Junbin Xiao, <strong>Pan Zhou</strong>, Tat-Seng Chua, Shuicheng Yan <br> European Conference on Computer Vision (<strong>ECCV</strong>), 2022 <br> <a href="https://arxiv.org/abs/2207.05342" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/VGT" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/VGT?style=social"> </iframe> </p> </li> <li> <p> <strong>Self-Promoted Supervision for Few-Shot Transformer</strong><br> Bowen Dong, <strong>Pan Zhou</strong>, Shuicheng Yan, Wangmeng Zuo <br> European Conference on Computer Vision (<strong>ECCV</strong>), 2022 <br> <a href="https://arxiv.org/abs/2203.07057" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/DongSky/few-shot-vit" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/DongSky/few-shot-vit?style=social"> </iframe> </p> </li> <li> <p> <strong>MetaFormer is Actually What You Need for Vision</strong><br> Weihao Yu, Mi Luo, <strong>Pan Zhou</strong>, Chenyang Si, Yichen Zhou, Xinchao Wang, Jiashi Feng, Shuicheng Yan <br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022 (<font color="#FF0000"><strong>oral</strong></font>) <br> <a href="https://arxiv.org/abs/2111.11418#:~:text=Based%20on%20the%20extensive%20experiments,on%20the%20token%20mixer%20modules." rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="https://github.com/sail-sg/poolformer" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/poolformer?style=social"> </iframe> </p> </li> <h4> <a name="2021"></a> 2021 </h4> <li> <p> <strong>A Hybrid Stochastic-Deterministic Minibatch Proximal Gradient Method for Efficient Optimization and Generalization</strong><br> <strong>Pan Zhou</strong>, XiaoTong Yuan, Zhouchen Lin, and Steven Hoi<br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2021<br> <a href="../assets/pdf/2021-TPAMI-HSDN.pdf">[PDF]</a> <a href="../assets/pdf/2021-TPAMI-HSDN-supp.pdf">[SUPP]</a> <a href="../assets/bibtex/2021-PAMI-HSDN-bib.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Efficient Gradient Support Pursuit with Less Hard Thresholding for Cardinality-Constrained Learning</strong><br> Fanhua Shang, Bingkun Wei, Hongying Liu, Yuanyuan Liu, <strong>Pan Zhou</strong>, and Maoguo Gong <br> IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>), 2021 <br> <a href="https://ieeexplore.ieee.org/abstract/document/9463415" rel="external nofollow noopener" target="_blank">[PDF]</a> </p> </li> <li> <p> <strong>A Theory-Driven Self-Labeling Refinement Method for Contrastive Representation Learning</strong><br> <strong>Pan Zhou</strong>, Caiming Xiong, Xiaotong Yuan, Steven Hoi<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2021 (<font color="#FF0000"><strong>spotlight</strong></font>) <br> <a href="../assets/pdf/2021-NIPS-SLR.pdf">[PDF]</a> <a href="../assets/pdf/2021-NIPS-SLR-supp.pdf">[SUPP]</a> <a href="https://arxiv.org/abs/2106.14749" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2021-NIPS-SLR-bib.txt">[Bibtex]</a> <a href="https://openreview.net/forum?id=P84bifNCpFQ&amp;referrer=%5BAuthor%20Console%5D" rel="external nofollow noopener" target="_blank">[Code]</a> <a href="../assets/pdf/2021-NIPS-SLR-Slide.pdf">[Slides]</a> <a href="../assets/pdf/2021-NIPS-SLR-poster.pdf">[Poster]</a> </p> </li> <li> <p> <strong>Towards Understanding Why Lookahead Generalizes Better Than SGD and Beyond</strong><br> <strong>Pan Zhou</strong>, Hanshu Yan, Xiaotong Yuan, Jiashi Feng, Shuicheng Yan<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2021 <br> <a href="../assets/pdf/2021-NIPS-LA.pdf">[PDF]</a> <a href="../assets/pdf/2021-NIPS-LA-supp.pdf">[SUPP]</a> <a href="../assets/bibtex/2021-NIPS-LA-bib.txt">[Bibtex]</a> <a href="https://github.com/sail-sg/SLRLA-optimizer" rel="external nofollow noopener" target="_blank">[Code]</a> <a href="../assets/pdf/2021-NIPS-LA-Slide.pdf">[Slides]</a> <a href="../assets/pdf/2021-NIPS-LA-poster.pdf">[Poster]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/sail-sg/SLRLA-optimizer?style=social"> </iframe> </p> </li> <li> <p> <strong>Task Similarity Aware Meta Learning: Theory-inspired Improvement on MAML</strong><br> <strong>Pan Zhou</strong>, Yingtian Zou, XiaoTong Yuan, Jiashi Feng, Caiming Xiong, and Steven Hoi<br> International Conference on Uncertainty in Artificial Intelligence (<strong>UAI</strong>), 2021 (NeurIPS'20 Meta Learning Workshop Paper) <br> <a href="https://meta-learn.github.io/2020/papers/69_paper.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="https://meta-learn.github.io/2020/papers/69_supplementary.pdf" rel="external nofollow noopener" target="_blank">[SUPP]</a> <a href="https://github.com/Carbonaraa/TSA-MAML" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/Carbonaraa/TSA-MAML?style=social"> </iframe> </p> </li> <li> <p> <strong>Wav-BERT: Cooperative Acoustic and Linguistic Representation Learning for Low-Resource Speech Recognition</strong><br> Guolin Zheng, Yubei Xiao, Ke Gong, <strong>Pan Zhou</strong>, Xiaodan Liang, and Liang Lin<br> Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2021 (Findings) <br> <a href="https://arxiv.org/pdf/2109.09161.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> </p> </li> <li> <p> <strong>How Important is the Train-Validation Split in Meta-Learning?</strong><br> Yu Bai, Minshuo Chen, <strong>Pan Zhou</strong>, Tuo Zhao, Jason D. Lee, Sham Kakade, Huan Wang, Caiming Xiong<br> International Conference on Machine Learning (<strong>ICML</strong>), 2021 <br> <a href="https://arxiv.org/pdf/2010.05843.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> </p> </li> <li> <p> <strong>Prototypical Contrastive Learning of Unsupervised Representations</strong><br> Junnan Li, <strong>Pan Zhou</strong>, Caiming Xiong, and Steven Hoi<br> International Conference on Learning Representations (<strong>ICLR</strong>), 2021 <br> <a href="https://openreview.net/pdf?id=KmykpuSrjcq" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2021-ICLR-SSL.txt">[Bibtex]</a> <a href="https://blog.einstein.ai/prototypical-contrastive-learning-pushing-the-frontiers-of-unsupervised-learning/" rel="external nofollow noopener" target="_blank">[Blog]</a> <a href="https://github.com/salesforce/PCL" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/salesforce/PCL?style=social"> </iframe> </p> </li> <li> <p> <strong>Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation</strong><br> Shuai Lin, <strong>Pan Zhou</strong>, Xiaodan Liang, Jianheng Tang, Ruihui Zhao, Ziliang Chen and Liang Lin <br> Association for the Advancement of Artificial Intelligence (<strong>AAAI</strong>), 2021 <br> <a href="https://arxiv.org/pdf/2012.11988.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2021-AAAI-Medical.txt">[Bibtex]</a> <a href="https://github.com/ha-lins/GEML-MDG" rel="external nofollow noopener" target="_blank">[Code]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/ha-lins/GEML-MDG?style=social"> </iframe> </p> </li> <li> <p> <strong>Adversarial Meta Sampling for Multilingual Low-Resource Speech Recognition</strong><br> Yubei Xiao, Ke Gong, <strong>Pan Zhou</strong>, Guolin Zheng, Xiaodan Liang and Liang Lin <br> Association for the Advancement of Artificial Intelligence (<strong>AAAI</strong>), 2021 <br> <a href="https://arxiv.org/pdf/2012.11896.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2021-AAAI-ASR.txt">[Bibtex]</a> </p> </li> <h4> <a name="2020"></a> 2020 </h4> <li> <p> <strong>Theory-Inspired Path-Regularized Differential Network Architecture Search</strong><br> <strong>Pan Zhou</strong>, Caiming Xiong, Richard Socher, and Steven Hoi<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2020 (<font color="#FF0000"><strong>oral</strong></font>) <br> <a href="../assets/pdf/2020_NAS.pdf">[PDF]</a> <a href="../assets/pdf/2020_NAS_supp.pdf">[SUPP]</a> <a href="https://arxiv.org/pdf/2006.16537.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2020_NAS_bib.txt">[Bibtex]</a> <a href="https://blog.einstein.ai/theory-inspired-network-architecture-search/" rel="external nofollow noopener" target="_blank">[Blog]</a> <a href="https://github.com/salesforce/PR-DARTS" rel="external nofollow noopener" target="_blank">[Code]</a> <a href="../assets/pdf/2020-NIPS-NAS-slides.pdf">[Slides]</a> <a href="../assets/pdf/2020-NIPS-NAS-poster.pdf">[Poster]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/salesforce/PR-DARTS?style=social"> </iframe> </p> </li> <li> <p> <strong>Towards Theoretically Understanding Why SGD Generalizes Better Than ADAM in Deep Learning</strong><br> <strong>Pan Zhou</strong>, Jiashi Feng, Chao Ma, Caiming Xiong, Steven Hoi, and Weinan E<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2020<br> <a href="../assets/pdf/2020_generalization.pdf">[PDF]</a> <a href="../assets/pdf/2020_generalization_supp.pdf">[SUPP]</a> <a href="https://arxiv.org/pdf/2010.05627.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2020_generalization_bib.txt">[Bibtex]</a> <a href="https://github.com/salesforce/comparison_SGD_ADAM" rel="external nofollow noopener" target="_blank">[Code]</a> <a href="../assets/pdf/2020-NIPS-SGD-slides.pdf">[Slides]</a> <a href="../assets/pdf/2020-NIPS-SGD-poster.pdf">[Poster]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/salesforce/comparison_SGD_ADAM?style=social"> </iframe> </p> </li> <li> <p> <strong>Improving GAN Training with Probability Ratio Clipping and Sample Reweighting</strong><br> Yue Wu, <strong>Pan Zhou</strong>, Andrew Gordon Wilson, Eric Xing, and Zhiting Hu<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2020<br> <a href="../assets/pdf/2020_GAN.pdf">[PDF]</a> <a href="https://arxiv.org/pdf/2006.06900.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2020_GAN_bib.txt">[Bibtex]</a> <a href="https://github.com/Holmeswww/PPOGAN" rel="external nofollow noopener" target="_blank">[Codes]</a> <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://img.shields.io/github/stars/Holmeswww/PPOGAN?style=social"> </iframe> </p> </li> <li> <p> <strong>Hybrid Stochastic-Deterministic Minibatch Proximal Gradient: Less-Than-Single-Pass Optimization with Nearly Optimal Generalization</strong><br> <strong>Pan Zhou</strong> and Xiaotong Yuan<br> International Conference on Machine Learning (<strong>ICML</strong>), 2020 <br> <a href="../assets/pdf/2020_hybrid_proximal_minibatch.pdf">[PDF]</a> <a href="https://arxiv.org/pdf/2009.09835.pdf" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2020_optimization_bib.txt">[Bibtex]</a> </p> </li> <h4> <a name="2019"></a> 2019 </h4> <li> <p> <strong>Tensor Low-rank Representation for Data Recovery and Clustering</strong><br> <strong>Pan Zhou</strong>, Canyi Lu, Jiashi Feng, Zhouchen Lin, Shuicheng Yan<br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2019 <br> <a href="../assets/pdf/2019-TPAMI-tensor.pdf">[PDF]</a> <a href="../assets/pdf/2019-TPAMI-tensor-supp.pdf">[SUPP]</a> <a href="../assets/bibtex/2019-PAMI-tensor.txt">[Bibtex]</a> <a href="../assets/code/TLRR-code.zip">[Codes]</a> </p> </li> <li> <p> <strong>Faster First-Order Methods for Stochastic Non-Convex Optimization on Riemannian Manifolds</strong><br> <strong>Pan Zhou</strong>, Xiaotong Yuan, Shuicheng Yan, Jiashi Feng<br> IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2019 <br> <a href="https://ieeexplore.ieee.org/document/8792163" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="../assets/bibtex/2019-PAMI-RSPIDER.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Efficient Meta Learning via Minibatch Proximal Update</strong><br> <strong>Pan Zhou</strong>, Xiaotong Yuan, Huan Xu, Shuicheng Yan, Jiashi Feng<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2019 (<font color="#FF0000"><strong>spotlight</strong></font>) <br> <a href="../assets/pdf/2019-NIPS-metaleanring.pdf">[PDF]</a> <a href="../assets/pdf/2019-NIPS-metaleanring-supplementary.pdf">[SUPP]</a> <a href="../assets/bibtex/2019-NIPS-meta.txt">[Bibtex]</a> <a href="../assets/code/MetaMinibatchProx.zip">[Codes]</a> <a href="../assets/pdf/2019neurips-slides.pdf">[Slides]</a> <a href="../assets/pdf/2019-NIPS-poster.pdf">[Poster]</a> </p> </li> <li> <p> <strong>Generalized Majorization-Minimization for Non-Convex Optimization</strong><br> Hu Zhang, <strong>Pan Zhou</strong>, Yi Yang, Jiashi Feng<br> International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2019 <br> <a href="https://www.ijcai.org/proceedings/2019/0591.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="../assets/bibtex/2019-IJCAI-MM.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Faster First-Order Methods for Stochastic Non-Convex Optimization on Riemannian Manifolds</strong><br> <strong>Pan Zhou</strong>, Xiaotong Yuan, Jiashi Feng<br> International Conference on Artificial Intelligence and Statistics (<strong>AISTATS</strong>), 2019 <br> <a href="https://arxiv.org/pdf/1811.08109.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="../assets/bibtex/2019-AISTATIC-RSPIDER.txt">[Bibtex]</a> </p> </li> <h4> <a name="2018"></a> 2018 </h4> <li> <p> <strong>Efficient Stochastic Gradient Hard Thresholding</strong><br> <strong>Pan Zhou</strong>, Xiaotong Yuan, Jiashi Feng<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2018 <br> <a href="http://papers.nips.cc/paper/7469-efficient-stochastic-gradient-hard-thresholding" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="../assets/bibtex/2018-NIPS-hardthresholding.txt">[Bibtex]</a> <a href="../assets/code/HSGHTcode.rar">[Codes]</a> </p> </li> <li> <p> <strong>New Insight into Hybrid Stochastic Gradient Descent: Beyond With-Replacement Sampling and Convexity</strong><br> <strong>Pan Zhou</strong>, Xiaotong Yuan, Jiashi Feng<br> Neural Information Processing Systems (<strong>NeurIPS</strong>), 2018 <br> <a href="http://papers.nips.cc/paper/7399-new-insight-into-hybrid-stochastic-gradient-descent-beyond-with-replacement-sampling-and-convexity" rel="external nofollow noopener" target="_blank">[PDF]</a> <a href="../assets/bibtex/2018-NIPS-withreplacement.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Understanding Generalization and Optimization Performance of Deep CNNs</strong><br> <strong>Pan Zhou</strong>, Jiashi Feng<br> International Conference on Machine Learning (<strong>ICML</strong>), 2018 <br> <a href="../assets/pdf/2018-ICML-deepCNNs.pdf">[PDF]</a> <a href="https://arxiv.org/abs/1805.10767" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2018-ICML-AnalysisCNN.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Deep Adversarial Subspace Clustering</strong><br> <strong>Pan Zhou</strong>, Yunqing Hou, Jiashi Feng<br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018 <br> <a href="../assets/pdf/2018-CVPR-DSCN.pdf">[PDF]</a> <a href="../assets/code/dsc_code.zip">[Codes]</a> <a href="../assets/bibtex/2018-CVPR-DSCN.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Empirical Risk Landscape Analysis for Understanding Deep Neural Networks</strong><br> <strong>Pan Zhou</strong>, Jiashi Feng<br> International Conference on Learning Representations (<strong>ICLR</strong>), 2018 <br> <a href="../assets/pdf/2018-ICLR-AnalysisDNN.pdf">[PDF]</a> <a href="https://arxiv.org/abs/1705.07038" rel="external nofollow noopener" target="_blank">[Axriv]</a> <a href="../assets/bibtex/2018-ICLR-AnalysisDNN.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Task Relation Networks</strong><br> Jianshu Li, <strong>Pan Zhou</strong>, Yunpeng Chen, Jian Zhao, Sujoy Roy, Yan Shuicheng, Jiashi Feng, and Terence Sim<br> IEEE Winter Conference on Applications of Computer Vision (<strong>WACV</strong>), 2019 <br> <a href="https://ieeexplore.ieee.org/document/8658407" rel="external nofollow noopener" target="_blank">[PDF]</a> </p> </li> <h4> <a name="2017"></a> 2017 </h4> <li> <p> <strong>Tensor Factorization for Low-Rank Tensor Completion</strong><br> <strong>Pan Zhou</strong>, Canyi Lu, Zhouchen Lin, Chao Zhang<br> IEEE Transactions on Image Processing (<strong>TIP</strong>), 2017 <br> <a href="../assets/pdf/2017-TIP-TCTF.pdf">[PDF]</a> <a href="../assets/pdf/2017-TIP-TCTF-supplementary.pdf">[SUPP]</a> <a href="../assets/code/TCTF_code.rar">[Codes]</a> <a href="../assets/bibtex/2017-TIP-TCTF.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Dictionary Learning with Structured Noise</strong><br> <strong>Pan Zhou</strong>, Cong Fang, Zhouchen Lin, Chao Zhang, Edward Y. Chang<br> Neurocomputing, 2017 <br> <a href="../assets/pdf/2017-NEUCOM-DLSN.pdf">[PDF]</a> <a href="../assets/bibtex/2017-NEUCOM-DLSN.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Feature Learning via Partial Differential Equation with Applications to Face Recognition</strong><br> Cong Fang, Zhenyu Zhao, <strong>Pan Zhou</strong>, Zhouchen Lin<br> Pattern Recognition (<strong>PR</strong>), 2017 <br> <a href="../assets/pdf/2017-PR-FE-PDE.pdf">[PDF]</a> <a href="../assets/code/LPDE_featurelearning_code.rar">[Codes]</a> <a href="../assets/bibtex/2017-PR-FE-PDE.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Outlier-Robust Tensor PCA</strong><br> <strong>Pan Zhou</strong>, Jiashi Feng<br> IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2017 <br> <a href="../assets/pdf/2017-CVPR-RTPCA.pdf">[PDF]</a> <a href="../assets/pdf/2017-CVPR-RTPCA-supp.pdf">[SUPP]</a> <a href="../assets/code/OR_TPCA_code.rar">[Codes]</a> <a href="../assets/bibtex/2017-CVPR-TRPCA.txt">[Bibtex]</a> </p> </li> <h4> <a name="2016"></a> 2016 </h4> <li> <p> <strong>Bilevel Model Based Discriminative Dictionary Learning for Recognition</strong><br> <strong>Pan Zhou</strong>, Chao Zhang, Zhouchen Lin<br> IEEE Transactions on Image Processing (<strong>TIP</strong>), 2016 <br> <a href="../assets/pdf/2016-TIP-bilevel.pdf">[PDF]</a> <a href="../assets/pdf/2016-TIP-bilevel-supp.pdf">[SUPP]</a> <a href="../assets/bibtex/2016-TIP-bilevel.txt">[Bibtex]</a> </p> </li> <li> <p> <strong>Integrated Low-Rank-Based Discriminative Feature Learning for Recognition</strong><br> <strong>Pan Zhou</strong>, Zhouchen Lin, Chao Zhang<br> IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>), 2016 <br> <a href="../assets/pdf/2016-TNNLS-Integrated-Low-Rank.pdf">[PDF]</a> <a href="../assets/pdf/2016-TNNLS-Integrated-Low-Rank-supp.pdf">[SUPP]</a> <a href="../assets/code/integrated_low_rank%20code.rar">[Codes]</a> <a href="../assets/bibtex/2016-TNNLS-Integrated-Low-Rank.txt">[Bibtex]</a> </p> </li> </ol> <p><br></p> <h5 id="books-and-patents"><strong>Books and Patents</strong></h5> <ol class="biblist"> <li> <p> <strong>Tensors for Data Processing</strong><br> Chapter 6 is contributed by <strong>Pan Zhou</strong>, Canyi Lu, Zhouchen Lin <br> Elsevier, 2022. <a href="https://www.sciencedirect.com/science/article/abs/pii/B9780128244470000121" rel="external nofollow noopener" target="_blank">[PDF]</a> </p> </li> <li> <p> <strong>Neural network based scene text recognition</strong><br> <strong>Pan Zhou</strong>, Peng Tang, Ran Xu, Chu Hong Hoi<br> US Patent, 2022. <a href="https://patentimages.storage.googleapis.com/2c/b3/d2/d0a3dcc343b870/US20220237403A1.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> </p> </li> <li> <p> <strong>Systems and methods for contrastive learning with self-labeling refinement</strong><br> <strong>Pan Zhou</strong>, Caiming Xiong, Chu Hong Hoi<br> US Patent, 2022. <a href="https://patentimages.storage.googleapis.com/26/48/86/29fb78a23ee73c/US20220269946A1.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> </p> </li> <li> <p> <strong>System and method for differential architecture search for neural networks</strong><br> <strong>Pan Zhou</strong>, Chu Hong Hoi<br> US Patent, 2021. <a href="https://patentimages.storage.googleapis.com/ea/8a/b2/ed2e17a1d3937e/US20210383188A1.pdf" rel="external nofollow noopener" target="_blank">[PDF]</a> </p> </li> </ol> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Pan ZHOU. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>